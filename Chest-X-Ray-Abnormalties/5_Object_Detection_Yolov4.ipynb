{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_Detection_Yolov4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqKVghy1RRh5"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LrQ_fSTRSSL",
        "outputId": "561ba489-ce4c-487c-d9f5-cfe265a0710b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgd-3wnaRUC1",
        "outputId": "300da4b8-7c67-4b94-9422-8caa16cb88e4"
      },
      "source": [
        "# check whether GPU is provided\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tATQukyU2ok2"
      },
      "source": [
        "#Data Preparation Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7rG9emsRX0V"
      },
      "source": [
        "#class of important functions\n",
        "#Yolo format rules \n",
        "''' \n",
        "x_center=( (x_max-x_min)/2 + x_min)/ image_with \n",
        "y_center=( (y_max-y_min)/2 + y_min)/ image_with\n",
        "width   =(x_max-x_min)/image_width\n",
        "height\t=(y_max-y_min)/image_height'''\n",
        "\n",
        "class Preparator:\n",
        "\n",
        "  def __init__(self,csv_path):\n",
        "    self.csv=pd.read_csv(csv_path)\n",
        "    self.number_of_classes=len(self.csv.class_name.unique())-1 #-1 here because we removed normal class \n",
        "\n",
        "  def drop_normal_images(self):\n",
        "    print('befor dropping size = ',len(self.csv))\n",
        "    self.csv=self.csv.dropna()\n",
        "    print('after dropping dropping size = ',len(self.csv))\n",
        "    return self.csv\n",
        "\n",
        "\n",
        "  def write_into_file(self,file_path='',file_name='',lst=[]):\n",
        "\n",
        "    #open a classes.names file to write class names into it \n",
        "    outF = open(file_path + file_name, \"w\")\n",
        "\n",
        "    #write class names line by line \n",
        "    for line in lst:\n",
        "      outF.write(line)\n",
        "      outF.write(\"\\n\")\n",
        "    outF.close()\n",
        "\n",
        "\n",
        "  def create_class_names(self,output_path='/content/drive/MyDrive/',file_name=''):\n",
        "\n",
        "    #open csv file and extract class names except(no finding)\n",
        "    self.class_names=sorted(self.csv.class_name.unique())\n",
        "    del self.class_names[self.class_names.index('No finding')]\n",
        "\n",
        "    #write the list into file line by line\n",
        "    self.write_into_file(output_path,file_name,self.class_names)\n",
        "\n",
        "\n",
        "  def create_train_test_txt(self,train_path='/content/drive/MyDrive/',output_path='/content/drive/MyDrive/',exten='.jpg'):\n",
        "\n",
        "    self.image_ids= train_path + self.csv.image_id.unique()+exten\n",
        "    self.imade_ids=self.image_ids.tolist()\n",
        "\n",
        "    #shuffle our dataset\n",
        "    random.shuffle(self.image_ids)\n",
        "    \n",
        "    #write into train file 80%\n",
        "    print(int(len(self.image_ids)*(80/100)))\n",
        "    self.write_into_file(output_path,'train.txt',self.image_ids[0: int(len(self.image_ids)*(80/100)) ])\n",
        "\n",
        "    #write into test file 20%\n",
        "    print(len(self.image_ids[int(len(self.image_ids)*(80/100)):: ]))\n",
        "    self.write_into_file(output_path,'test.txt',self.image_ids[int(len(self.image_ids)*(80/100)):: ])\n",
        "    \n",
        "\n",
        "  def convert_to_yolo_format(self,class_id,x_min,y_min,x_max,y_max,height=1,width=1):\n",
        "    # note that all of these numbers are normalized \n",
        "    x_center =( (x_max-x_min)/2 + x_min)/ width \n",
        "    y_center =( (y_max-y_min)/2 + y_min)/ height\n",
        "    rec_width    =(x_max-x_min)/ width\n",
        "    rec_height\t =(y_max-y_min)/ height\n",
        "    #print(class_id,\"%.6f\"%x_center,\"%.6f\"%y_center,\"%.6f\"%rec_width,\"%.6f\"%rec_height) to visualize the output \n",
        "    return class_id,\"%.6f\"%x_center,\"%.6f\"%y_center,\"%.6f\"%rec_width,\"%.6f\"%rec_height\n",
        "\n",
        "\n",
        "  def create_object_file(self,output_path='',train_path='',test_path='',names_path='',backup_path=''):\n",
        "    classes_number=self.number_of_classes\n",
        "    file_name='obj.data'\n",
        "    outF = open(output_path + file_name, \"w\")\n",
        "    outF.write('classes= '+str(classes_number)+'\\n')\n",
        "    outF.write('train= '+train_path+'\\n')\n",
        "    outF.write('valid= '+test_path+'\\n')\n",
        "    outF.write('names= '+names_path+'\\n')\n",
        "    outF.write('backup= '+backup_path+'\\n')\n",
        "\n",
        "\n",
        "  def create_txt_for_each_image(self, path_for_height_width_file='',path_for_dataset=''):\n",
        "\n",
        "    hw_csv = pd.read_csv( path_for_height_width_file )\n",
        "    image_ids=self.csv.image_id.unique().tolist()\n",
        "\n",
        "    for image in image_ids:\n",
        "\n",
        "      #get height and width for this image\n",
        "      #.values to convert it to numpy array \n",
        "      #.reshape(-1) to flatting 2d array to be 1d array \n",
        "      #to list to convert numpy array to list to be able ti use it \n",
        "      h,w= hw_csv.query('image_id==@image')[['height','width']].values.reshape(-1).tolist()\n",
        "      \n",
        "      #get all images with same image id \n",
        "      df =self.csv.query(\"image_id==@image\")\n",
        "\n",
        "      #group bound boxes for each class then get single bound box by taking the mean of them \n",
        "      bboxes_df = df.groupby('class_id')[['class_id','x_min','y_min','x_max','y_max']].mean().round()\n",
        "      print(bboxes_df)\n",
        "\n",
        "      #open text file to write to it\n",
        "      outF = open(path_for_dataset + image +'.txt', \"w\")\n",
        "\n",
        "      for i in range(len(bboxes_df)):\n",
        "        class_name,x_center,y_center,width,height = self.convert_to_yolo_format(bboxes_df.iloc[i,0],\n",
        "                                                                        bboxes_df.iloc[i,1],\n",
        "                                                                        bboxes_df.iloc[i,2],\n",
        "                                                                        bboxes_df.iloc[i,3],\n",
        "                                                                        bboxes_df.iloc[i,4], h,w)\n",
        "        line=str(class_name)+\" \"+str(x_center)+\" \"+str(y_center)+\" \"+str(width)+\" \"+str(height)+\"\\n\"\n",
        "        outF.write(line)\n",
        "\n",
        "      outF.close()\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQTt-y-GlzH9"
      },
      "source": [
        "#preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rz6PPAwRZ7n"
      },
      "source": [
        "\n",
        "#prep=Preparator('/content/drive/MyDrive/Detection/train.csv')\n",
        "#prep.create_class_names('/content/drive/MyDrive/Detection/','classes.names')\n",
        "#prep.drop_normal_images()\n",
        "#prep.create_train_test_txt('/content/drive/MyDrive/Detection/darknet_for_colab/data/chestxray256/','/content/drive/MyDrive/Detection/darknet_for_colab/data/')\n",
        "#prep.create_txt_for_each_image(\"/content/drive/MyDrive/Detection/image_height_width.csv\",\"/content/drive/MyDrive/dataset/chest xray256/\")\n",
        "#prep.create_object_file('/content/drive/MyDrive/Detection/darknet_for_colab/data/','/content/drive/MyDrive/Detection/darknet_for_colab/data/train.txt','/content/drive/MyDrive/Detection/darknet_for_colab/data/test.txt','/content/drive/MyDrive/Detection/darknet_for_colab/data/classes.names','/content/drive/MyDrive/Detection/darknet_for_colab/backup')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSkUtjkLyp94",
        "outputId": "3fcd1e18-f4a4-40b6-f456-1ba118f4f3af"
      },
      "source": [
        "dataset=os.listdir('/content/drive/MyDrive/dataset/chest xray256/')\n",
        "csv=pd.read_csv('/content/drive/MyDrive/Detection/train.csv').image_id.unique()+'.jpg'\n",
        "csv=csv.tolist()counter=0\n",
        "for image_id in dataset:\n",
        "  if image_id not in csv: \n",
        "    if '.txt' not in image_id:\n",
        "      counter+=1\n",
        "      print('remove this image_id ',image_id)\n",
        "      #os.remove('/content/drive/MyDrive/dataset/chest xray256/'+image_id)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjmogCES2N9I"
      },
      "source": [
        "#Setup Darknet Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ECZag72mhf",
        "outputId": "19df7b7f-529a-4200-ff9d-24d43bc4c6a1"
      },
      "source": [
        "assert os.getcwd()=='/content/drive/My Drive/Detection','Directory should be \"/content/drive/My Drive/Detection\" instead of {}'.format(os.getcwd())\n",
        "!git clone https://github.com/quangnhat185/darknet_for_colab.git\n",
        "%cd darknet_for_colab\n",
        "!make\n",
        "!chmod +x ./darknet.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet_for_colab'...\n",
            "remote: Enumerating objects: 1083, done.\u001b[K\n",
            "remote: Total 1083 (delta 0), reused 0 (delta 0), pack-reused 1083\u001b[K\n",
            "Receiving objects: 100% (1083/1083), 5.16 MiB | 6.99 MiB/s, done.\n",
            "Resolving deltas: 100% (233/233), done.\n",
            "Checking out files: 100% (977/977), done.\n",
            "/content/drive/My Drive/Detection/darknet_for_colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tga0Ygcs6ob_"
      },
      "source": [
        "# Download yolov4 pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APveUxZ66ySF",
        "outputId": "1f527453-fe90-4481-d4fc-110e210e96c2"
      },
      "source": [
        "assert os.getcwd()=='/content/drive/My Drive/Detection/darknet_for_colab', 'Directory should be \"/content/drive/My Drive/Detection/darknet_for_colab\" instead of \"{}\"'.format(os.getcwd())\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 11:41:31--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/75388965/48bfe500-889d-11ea-819e-c4d182fcf0db?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210708T114132Z&X-Amz-Expires=300&X-Amz-Signature=2afd72637eea0aeaa773655d284cf03f271ed22efa2b2c8eb2f9f2228e5c323e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.conv.137&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-07-08 11:41:32--  https://github-releases.githubusercontent.com/75388965/48bfe500-889d-11ea-819e-c4d182fcf0db?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210708T114132Z&X-Amz-Expires=300&X-Amz-Signature=2afd72637eea0aeaa773655d284cf03f271ed22efa2b2c8eb2f9f2228e5c323e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.conv.137&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170038676 (162M) [application/octet-stream]\n",
            "Saving to: ‘yolov4.conv.137’\n",
            "\n",
            "yolov4.conv.137     100%[===================>] 162.16M  37.2MB/s    in 4.4s    \n",
            "\n",
            "2021-07-08 11:41:36 (36.7 MB/s) - ‘yolov4.conv.137’ saved [170038676/170038676]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6b1jrtDeFO"
      },
      "source": [
        "#chestX-ray dataset (yolo format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ElPFGSyiDzr5",
        "outputId": "850319fc-b5d2-4a70-cdb0-29a9e4ebae49"
      },
      "source": [
        "#%cd data \n",
        "assert os.getcwd()=='//content/drive/My Drive/Detection/darknet_for_colab/data', 'Directory should be \"//content/drive/My Drive/Detection/darknet_for_colab/data\" instead of \"{}\"'.format(os.getcwd())\n",
        "'''# download custom data of common traffic signs\n",
        "!wget --no-check-certificate \"https://onedrive.live.com/download?cid=A86CBC7F31A1C06B&resid=A86CBC7F31A1C06B%21121&authkey=AMUUk0Np4tqH3n4\" -O ts.zip\n",
        "!unzip ts.zip\n",
        "!rm -f ts.zip\n",
        "!ls\n",
        "%cd ..'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Detection/darknet_for_colab/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C4haYq2WEP3I",
        "outputId": "9663e10e-00ec-4c22-80b3-b37c271c6c49"
      },
      "source": [
        "#make a copy of folder in google drive\n",
        "#os.chdir('path/for/the/folder')\n",
        "#%cp -av  folder_name copy_folder_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Detection/darknet_for_colab'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzzTIkIQI7gF"
      },
      "source": [
        "# Modify yolov4 architecture\n",
        "**Double click on file `yolov4_config.py` to modify the hyperpameters directly from Colab environment**\n",
        "\n",
        "E.g: I will train my dataset with these parameters:\n",
        " - classes= 14, \n",
        " - max_batches=8000\n",
        " - batch=64\n",
        " - subdivisions=16\n",
        " - width=256\n",
        " - height=256\n",
        " - ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdEVn_DYLKOi",
        "outputId": "66493352-f5e9-4853-991c-1fd964c42f59"
      },
      "source": [
        "#os.chdir('/content/drive/MyDrive/Detection/darknet_for_colab/')\n",
        "#assert os.getcwd()=='/content/drive/MyDrive/Detection/darknet_for_colab', 'Directory should be \"/content/drive/MyDrive/Detection/darknet_for_colab\" instead of \"{}\"'.format(os.getcwd())\n",
        "\n",
        "# Run python script to create our customize yolov4_custom_train.cfg \n",
        "# and yolov4_custom_tes.cfg in folder /cfg\n",
        "!python yolov4_setup.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Generating yolov4_custom_train.cfg successfully...\n",
            "[INFO] Generating yolov4_custom_test.cfg successfully...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqWXlAg5m6t8"
      },
      "source": [
        "#Create Symbolic Link In Our Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCy8u1seLgHC"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Detection/darknet_for_colab')\n",
        "assert os.getcwd()=='/content/drive/My Drive/Detection/darknet_for_colab', 'Directory should be \"/content/drive/My Drive/Detection/darknet_for_colab\" instead of \"{}\"'.format(os.getcwd())\n",
        "\n",
        "# delete backup folder from our \n",
        "!rm /content/drive/'My Drive'/Detection/darknet_for_colab/backup -r\n",
        "\n",
        "# create Symlinks so we can save trained weight in our Google Drive\n",
        "# create folder YOLOv4_weight/back in your Drive to store trained weights\n",
        "!ln -s /content/drive/'My Drive'/YOLOv4_weight/backup /content/drive/'My Drive'/Detection/darknet_for_colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kku2G_5Ppcb3"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGiQornzqOBe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}